<!DOCTYPE html>
<!-- 
    FACE MAPPER - CAMERA ACCESS BYPASSED
    
    This file has been modified to bypass camera access requirements.
    To run without camera permissions:
    1. Open this file in a web browser
    2. The app will run in demo mode with a mock video stream
    3. No camera access will be requested
    
    If you want to restore camera access, you'll need to:
    1. Serve this file from a localhost server (not file:// protocol)
    2. Use HTTPS or localhost (secure context required for camera)
    3. Grant camera permissions when prompted

    Run the file with: python -m http.server 8000
    And open the browser to http://localhost:8000
-->
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        :root { 
            --bg: transparent; 
            --led-off: #121212; 
            --led-on: #ffff00;
            --grid-bg: #000000;
        }
        
        html, body { 
            height: 100%; 
            margin: 0; 
            background: var(--bg); 
            font-family: Arial, sans-serif;
        }
        
        canvas#threeCanvas {
            position: fixed;
            top: 0;
            left: 0;
            z-index: 2; /* Bring Three.js canvas above UI for testing */
            width: 100%;
            height: 100%;
            pointer-events: none; /* Clicks pass through */
        }


        .group {
            display: flex;
            flex-direction: row;
            align-items: center;
            gap: 20px;
            justify-content: center;
            position: relative;
            z-index: 1;
        }
        
        .container {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            padding: 20px;
            height: 100%;
            gap: 20px;
            position: relative;
            z-index: 1;
        }
        
        .led-board {
            background: var(--grid-bg);
            border-radius: 10px;
            padding: 20px;
            display: grid; /* Restore LED board display */
            grid-template-columns: repeat(16, 1fr);
            gap: 2px;
            width: min(90vmin, 680px);
            height: min(90vmin, 680px);
            position: relative;
            z-index: 1;
        }
        
        .led {
            background: var(--led-off);
            border-radius: 20%;
            width: 100%;
            height: 100%;
            transition: all 0.2s ease;
            transform: translateZ(10px);
            transition: transform 0.3s ease, box-shadow 0.2s ease;
            perspective: 800px;
        }
        
        .led.on {
            background: var(--led-on);
            box-shadow: 0 0 15px rgba(255, 255, 0, 0.6);
            transform: translateZ(30px);
        }
        
        .camera-preview {
            width: min(90vmin, 680px);
            height: min(90vmin, 680px);
            background: #000;
            border-radius: 12px;
            overflow: hidden;
            border: 2px solid #333;
            position: relative;
            display: none !important;
        }
        
        .camera-preview video {
            width: 100%;
            height: 100%;
            object-fit: contain; /* Maintain aspect ratio */
            transform: scaleX(-1) !important; /* Mirror the camera feed */
            display: block;
            border-radius: 10px; /* Match container border radius */
            background: #000; /* Black background for letterboxing */
        }
        
        .camera-preview canvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            pointer-events: none;
            z-index: 2;
            transform: scaleX(-1) !important; /* Mirror the canvas overlay too */
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body>
    <div class="container">        
        <div class="status" id="status">
            <span class="face-indicator" id="faceIndicator"></span>
        </div>
        
        <div class="group">
            
            <canvas id="threeCanvas" style="width:100%; height:100%; display:block;"></canvas>
            <div class="led-board" id="ledBoard" style="width:100%; height:100%; position:relative;"></div>              
            
            

            <div class="camera-preview">
                <video id="video" autoplay muted playsinline></video>
                <canvas id="debugCanvas"></canvas>
            </div>
        </div>
    </div>

        <!-- load UMD build of Three.js locally to expose global THREE -->
        <script defer src="three.min.js"></script>
  
        <!-- standalone Three.js init -->
        <script>
          window.addEventListener('load', () => {
            if (typeof initThreeJS === 'function') {
              console.log('üîµ Standalone initThreeJS');
              initThreeJS();
            } else {
              console.error('initThreeJS is not defined');
            }
          });
        </script>

    <!-- Native Browser Face Detection API -->
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>

    <script>
      let faceDetectionLoaded = false;
      let detectionStarted = false;
      let faceDetector = null;

      // Native browser Face Detection API initialization
      async function initializeFaceDetection() {
        try {
          console.log('Loading face-api.js models for detection and expressions...');
          // Use local models directory
          const MODEL_URL = '/models';
          // Load face-api.js models
          await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
          await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
          await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
          faceDetectionLoaded = true;
          console.log('‚úÖ face-api.js models loaded successfully');
          // Update status
          faceIndicator = document.getElementById('faceIndicator');
          // Start detection if camera active
          if (video && video.srcObject && video.videoWidth > 0) startFaceDetection();
        } catch (error) {
          console.error('Error loading face-api.js models:', error);
        }
      }

      // Face detection initialization moved to main DOMContentLoaded handler
    </script>

    <script>
        let isRunning = false;
        let video = null;
        let canvas = null;
        let ctx = null;
        let leds = [];
        let animationId = null;
        let faceIndicator = null;
        // Three.js globals for reuse
        let renderer, scene, camera;
        // Storage for 3D LED cubes
        let threeLEDCubes = [];

        function setupLEDs() {
            const board = document.getElementById('ledBoard');
            board.innerHTML = '';
            leds = [];
            
            for (let row = 0; row < 16; row++) {
                for (let col = 0; col < 16; col++) {
                    const led = document.createElement('div');
                    led.className = 'led';
                    led.dataset.row = row;
                    led.dataset.col = col;
                    
                    // Add ID for pattern functions
                    const index = row * 16 + col;
                    led.id = `led-${index}`;
                    
                    board.appendChild(led);
                    leds.push(led);
                }
            }
        }

        function clearAllLEDs() {
            leds.forEach(led => {
                led.classList.remove('on');
            });
        }

        function mapFaceToSmiley(faceRect) {
            if (!faceRect) {
                clearAllLEDs();
                if (faceIndicator) faceIndicator.classList.remove('detected');
                return;
            }

            const { x, y, width, height } = faceRect;
            const videoWidth = video.videoWidth;
            const videoHeight = video.videoHeight;
            
            // Clear previous LEDs
            clearAllLEDs();
            
            // Calculate face center and size
            const faceCenterX = x + width / 2;
            const faceCenterY = y + height / 2;
            const faceSize = Math.max(width, height);
            
            // Map face features to smiley pattern
            SMILEY_PATTERN.forEach(([row, col]) => {
                const index = row * 16 + col;
                if (leds[index]) {
                    // Calculate intensity based on face position and size
                    const ledCenterX = (col + 0.5) * (videoWidth / 16);
                    const ledCenterY = (row + 0.5) * (videoHeight / 16);
                    
                    // Distance from face center to LED
                    const distance = Math.sqrt(
                        Math.pow(ledCenterX - faceCenterX, 2) + 
                        Math.pow(ledCenterY - faceCenterY, 2)
                    );
                    
                    // Normalize distance by face size
                    const normalizedDistance = distance / faceSize;
                    
                    // Light up LED if it's within the face area
                    if (normalizedDistance < 0.8) {
                        const intensity = Math.max(0, 1 - normalizedDistance);
                        leds[index].classList.add('on');
                        
                        // Adjust brightness based on intensity
                        if (intensity > 0.5) {
                            leds[index].style.boxShadow = `0 0 ${15 + 10 * intensity}px rgba(255, 255, 0, ${0.6 + 0.4 * intensity})`;
                        }
                    }
                }
            });
            
            // Update face indicator
            if (faceIndicator) {
                faceIndicator.classList.add('detected');
            }
        }

        async function detectFaces() {
            if (!isRunning || !faceDetectionLoaded || !video || !canvas) return;
            
            try {
                // Create canvas context if not exists
                if (!ctx) ctx = canvas.getContext('2d');
                // Mirror canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Run face-api.js detection
                const detections = await faceapi
                    .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions();
                // Resize and match overlay dimensions
                const displaySize = { width: video.videoWidth, height: video.videoHeight };
                faceapi.matchDimensions(canvas, displaySize);
                const resized = faceapi.resizeResults(detections, displaySize);
                // Draw overlays
                faceapi.draw.drawDetections(canvas, resized);
                faceapi.draw.drawFaceLandmarks(canvas, resized);
                // Process expressions from resized results
                if (resized.length > 0) {
                    const expr = getDominantExpression(resized[0].expressions);
                    mapSimpleExpressionToLEDs(expr);
                    // Highlight tags
                    ['neutral','sad','happy','surprised','angry'].forEach(tag=>{
                        const el=document.getElementById(`tag-${tag}`);
                        if(el) el.classList.toggle('active', tag===expr);
                    });
                } else {
                    clearAllLEDs();
                    ['neutral','sad','happy','surprised','angry'].forEach(tag=>{document.getElementById(`tag-${tag}`)?.classList.remove('active');});
                    faceIndicator?.classList.remove('detected'); faceIndicator.textContent='';
                }
                
                animationId = requestAnimationFrame(detectFaces);
            } catch (error) {
                console.error('Face-api detection error:', error);
                animationId = requestAnimationFrame(detectFaces);
            }
        }


        // Real-time expression detection using video frame analysis
        let lastExpression = 'neutral';
        let expressionHistory = [];
        
        // Get the dominant facial expression
        function getDominantExpression(expressions) {
            let maxValue = 0;
            let dominantExpression = 'neutral';
            
            for (const [expression, value] of Object.entries(expressions)) {
                if (value > maxValue && value > 0.3) { // Threshold for confidence
                    maxValue = value;
                    dominantExpression = expression;
                }
            }
            
            return dominantExpression;
        }

        // Simple expression mapping based on face data
        function mapSimpleExpressionToLEDs(expression) {
            console.log('üî• mapSimpleExpressionToLEDs called with:', typeof expression, JSON.stringify(expression));
                clearAllLEDs();
            
            // Map detected expression to appropriate LED pattern
            const cleanExpression = String(expression).trim().toLowerCase();
            console.log('üéØ About to switch on cleaned:', cleanExpression);
            
            switch (cleanExpression) {
                case 'happy':
                    console.log('‚úÖ MATCHED HAPPY - Drawing happy face');
                    drawSmileyFace();
                    break;
                case 'sad':
                    console.log('‚úÖ MATCHED SAD - Drawing sad face');
                    drawSadFace();
                    break;
                case 'surprised':
                    console.log('‚úÖ MATCHED SURPRISED - Drawing surprised face');
                    drawSurprisedFace();
                    break;
                case 'neutral':
                    console.log('‚úÖ MATCHED NEUTRAL - Drawing neutral face');
                    drawNeutralFace();
                    break;
                case 'angry':
                    console.log('‚úÖ MATCHED ANGRY - Drawing angry face');
                    drawAngryFace();
                    break;
                default:
                    console.log('‚ùå DEFAULT CASE - Drawing neutral face, cleaned expression was:', cleanExpression);
                    drawNeutralFace();
                    break;
            }
        }

        // Map facial expressions to LED patterns (kept for compatibility)
        function mapExpressionToLEDs(expression, expressionValues) {
            clearAllLEDs();
            
            switch (expression) {
                case 'happy':
                    drawSmileyFace();
                    break;
                case 'sad':
                    drawSadFace();
                    break;
                case 'surprised':
                    drawSurprisedFace();
                    break;
                case 'angry':
                    drawAngryFace();
                    break;
                case 'fearful':
                    drawFearfulFace();
                    break;
                case 'disgusted':
                    drawDisgustedFace();
                    break;
                default:
                    drawNeutralFace();
            }
        }

        // LED Pattern Functions
        function drawSmileyFace() {
            console.log('üü° drawSmileyFace() CALLED - applying smiley pattern');
            // Happy face pattern based on Figma design
            const smileyPattern = [
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,1,0,0,1,1,0,0,1,1,0,0,1,0,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0],
                [0,0,1,0,0,0,1,0,0,1,0,0,0,1,0,0],
                [0,0,1,0,0,0,0,1,1,0,0,0,0,1,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
            ];
            applyLEDPattern(smileyPattern);
        }

        function drawSadFace() {
            // Sad face pattern based on Figma design
            const sadPattern = [
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,1,0,0,1,1,0,0,1,1,0,0,1,0,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,1,1,1,1,0,0,0,0,1,0],
                [0,0,1,0,0,1,0,0,0,0,1,0,0,1,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
            ];
            applyLEDPattern(sadPattern);
        }

        function drawSurprisedFace() {
            // surprised face pattern based on Figma design
            const surprisedPattern = [
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,1,0,0,1,1,0,0,1,1,0,0,1,0,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,1,1,1,1,0,0,0,0,1,0],
                [0,1,0,0,0,1,1,1,1,1,1,0,0,0,1,0],
                [0,0,1,0,0,1,1,1,1,1,1,0,0,1,0,0],
                [0,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
            ];
            applyLEDPattern(surprisedPattern);
        }

        function drawAngryFace() {
            const angryPattern = [
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,1,0,1,1,0,0,0,0,1,1,0,1,0,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,0,1,0,0,1,0,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,0,1,1,0,0,0,0,0,1,0],
                [0,0,1,0,0,0,1,1,1,1,0,0,0,1,0,0],
                [0,0,1,0,0,1,0,0,0,0,1,0,0,1,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
            ];
            applyLEDPattern(angryPattern);
        }

        function drawFearfulFace() {
            const fearfulPattern = [
                [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0],
                [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0],
                [0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0],
                [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],
                [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],
                [1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1],
                [1,0,0,0,1,1,1,1,1,1,1,1,0,0,0,1],
                [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
                [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
                [1,1,1,1,1,1,1,0,0,1,1,1,1,1,1,1],
                [1,1,1,1,1,1,0,0,0,0,1,1,1,1,1,1],
                [0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0],
                [0,1,1,1,1,1,1,0,0,1,1,1,1,1,1,0],
                [0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0],
                [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0],
                [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0]
            ];
            applyLEDPattern(fearfulPattern);
        }

        function drawDisgustedFace() {
            const disgustedPattern = [
                [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0],
                [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0],
                [0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0],
                [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],
                [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],
                [1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,1],
                [1,1,1,0,0,1,1,1,1,1,1,0,0,1,1,1],
                [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
                [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
                [1,1,1,1,0,1,1,1,1,1,1,0,1,1,1,1],
                [1,1,1,1,1,0,1,1,1,1,0,1,1,1,1,1],
                [0,1,1,1,1,1,0,0,0,0,1,1,1,1,1,0],
                [0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0],
                [0,0,1,1,1,1,1,1,1,1,1,1,1,1,0,0],
                [0,0,0,1,1,1,1,1,1,1,1,1,1,0,0,0],
                [0,0,0,0,0,1,1,1,1,1,1,0,0,0,0,0]
            ];
            applyLEDPattern(disgustedPattern);
        }

        function drawNeutralFace() {
            // No expression pattern based on Figma design
            const neutralPattern = [
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,1,1,0,0,1,1,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0],
                [0,0,1,0,0,1,1,1,1,1,1,0,0,1,0,0],
                [0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0],
                [0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0],
                [0,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0],
                [0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0],
                [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
            ];
            applyLEDPattern(neutralPattern);
        }

        // Apply LED pattern to grid
        function applyLEDPattern(pattern) {
            console.log('üî• APPLYING LED PATTERN - First few rows:', pattern.slice(0, 3));
            let ledsFound = 0;
            let ledsLit = 0;
            // Use global threeLEDCubes array

            
            for (let row = 0; row < 16; row++) {
                for (let col = 0; col < 16; col++) {
                    const index = row * 16 + col;
                    const led = document.getElementById(`led-${index}`);
                    if (led) {
                        ledsFound++;
                        if (pattern[row][col] === 1) {
                            led.classList.add('on');
                            ledsLit++;
                        } else {
                            led.classList.remove('on');
                        }
                    } else {
                        console.error(`LED not found: led-${index}`);
                    }
                }
            }
            console.log(`Applied pattern: ${ledsFound} LEDs found, ${ledsLit} LEDs lit`);

            // Also apply pattern to 3D cubes and re-render scene
            threeLEDCubes.forEach((cube, idx) => {
                const row = Math.floor(idx / 16);
                const col = idx % 16;
                if (pattern[row][col] === 1) {
                    cube.material.color.set(0xffff00);
                    cube.material.opacity = 1.0;
                } else {
                    cube.material.color.set(0x111111);
                    cube.material.opacity = 0.3;
                }
            });
            // Render updated LED cube colors
            if (renderer && scene && camera) renderer.render(scene, camera);
        }


        // Browser compatibility check
        function checkBrowserCompatibility() {
            const issues = [];
            
            // Check if we're in a secure context
            if (!window.isSecureContext) {
                issues.push('‚ö†Ô∏è Not in secure context (HTTPS required for camera access)');
            }
            
            // Check getUserMedia support
            if (!navigator.mediaDevices) {
                issues.push('‚ö†Ô∏è MediaDevices API not supported');
            } else if (!navigator.mediaDevices.getUserMedia) {
                issues.push('‚ö†Ô∏è getUserMedia not supported');
            }
            
            // Check Face Detection support (optional - will fallback to video analysis)
            if (typeof FaceDetector === 'undefined') {
                console.log('Native Face Detection API not available, will use video frame analysis');
            } else {
                console.log('‚úÖ Native Face Detection API available');
            }
            
            return issues;
        }

        async function startFaceDetection() {
            try {
                // Get existing video element (should already be initialized by autoStartCamera)
                video = document.getElementById('video');
                if (!video) {
                    throw new Error('Video element not found');
                }
                
                // If camera is not already running, start it
                if (!video.srcObject) {
                    console.log('No existing camera stream, starting new one...');
                    const cameraStarted = await autoStartCamera();
                    if (!cameraStarted) {
                        throw new Error('Failed to start camera');
                    }
                } else {
                    console.log('Camera stream already active, checking status...');
                    console.log('Video srcObject:', video.srcObject);
                    console.log('Video readyState:', video.readyState);
                    console.log('Video paused:', video.paused);
                }
                
                // Setup canvas for face detection overlay
                canvas = document.getElementById('debugCanvas');
                if (!canvas) {
                    console.error('Debug canvas not found!');
                    return;
                }
                
                // Ensure canvas is visible and properly positioned
                canvas.style.display = 'block';
                canvas.style.position = 'absolute';
                canvas.style.top = '0';
                canvas.style.left = '0';
                canvas.style.pointerEvents = 'none'; // Don't interfere with video
                canvas.style.zIndex = '10'; // Above video but below UI
                
                console.log('Canvas setup complete - face detection overlay ready');
                
                // Set canvas size to match video when ready
                video.addEventListener('loadedmetadata', () => {
                    if (canvas) {
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        console.log(`Canvas resized to match video: ${canvas.width}x${canvas.height}`);
                    }
                });
                
                // Ensure video is playing
                if (video.paused) {
                    console.log('Video is paused, attempting to play...');
                    try {
                        await video.play();
                        console.log('Video play successful');
                    } catch (playError) {
                        console.error('Video play failed:', playError);
                    }
                } else {
                    console.log('Video is already playing');
                }
                
                if (faceDetectionLoaded) {
                    faceIndicator = document.getElementById('faceIndicator');
                    
                    isRunning = true;
                    detectFaces();
                    
                    document.getElementById('startBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;
                } else {
                    faceIndicator = document.getElementById('faceIndicator');
                }
                
            } catch (error) {
                const errorMsg = error.message || 'Unknown error';
                faceIndicator = document.getElementById('faceIndicator');
                
                const cameraStatus = document.getElementById('cameraStatus');
                cameraStatus.textContent = `Camera: Error - ${errorMsg}`;
                cameraStatus.style.background = 'rgba(255,0,0,0.8)';
                
                console.error('Camera start error:', error);
            }
        }

        // Removed duplicate testCameraOnly function - using autoStartCamera instead

        function stopFaceDetection() {
            isRunning = false;
            if (animationId) {
                cancelAnimationFrame(animationId);
                animationId = null;
            }
            
            // Hide the canvas overlay when face detection stops
            if (canvas) {
                canvas.style.display = 'none';
                console.log('Canvas overlay hidden - face detection stopped');
            }
            
            // Don't stop the camera stream - keep it running
            // Only stop face detection, but leave camera active
            
            // Keep camera status as active
                const cameraStatus = document.getElementById('cameraStatus');
            if (video && video.srcObject && video.videoWidth > 0) {
                cameraStatus.textContent = `Camera: Active (${video.videoWidth}x${video.videoHeight})`;
                cameraStatus.style.background = 'rgba(0,255,0,0.8)';
            } else {
                cameraStatus.textContent = 'Camera: Ready';
                cameraStatus.style.background = 'rgba(0,0,0,0.8)';
            }
            
            clearAllLEDs();
            faceIndicator = document.getElementById('faceIndicator');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }

        // Auto-start camera function
        async function autoStartCamera() {
            try {
                console.log('üü¢ autoStartCamera() CALLED - initializing camera with mirroring');
                // Setup video element first
                video = document.getElementById('video');
                
                // Debug current video transform
                if (video) {
                    console.log('Current video transform before:', video.style.transform);
                    console.log('Current video computed style:', window.getComputedStyle(video).transform);
                }
                if (!video) {
                    console.error('Video element not found');
                    return false;
                }
                
                // Check if we're in a secure context
                if (!window.isSecureContext) {
                    console.warn('Not in secure context - using mock camera');
                    video.srcObject = createMockCamera();
                    video.style.display = 'block';
                    video.style.setProperty('transform', 'scaleX(-1)', 'important'); // Mirror the video horizontally
                    video.play();
                    
                    const cameraStatus = document.getElementById('cameraStatus');
                    if (cameraStatus) {
                        cameraStatus.textContent = 'Camera: Demo Mode (Use localhost:8000 for real camera)';
                        cameraStatus.style.background = 'rgba(255,165,0,0.8)';
                    }
                    return true;
                }
                
                // Check if getUserMedia is available
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    console.warn('getUserMedia not available - using mock camera');
                    video.srcObject = createMockCamera();
                    video.style.display = 'block';
                    video.style.setProperty('transform', 'scaleX(-1)', 'important'); // Mirror the video horizontally
                    video.play();
                    
                    const cameraStatus = document.getElementById('cameraStatus');
                    if (cameraStatus) {
                        cameraStatus.textContent = 'Camera: Demo Mode (Media API not supported)';
                        cameraStatus.style.background = 'rgba(255,165,0,0.8)';
                    }
                    return true;
                }
                
                // Try to request camera access
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        width: { ideal: 1280, min: 640 },
                        height: { ideal: 720, min: 480 },
                        facingMode: 'user',
                        frameRate: { ideal: 30 }
                    },
                    audio: false
                });
                
                // Set video source and ensure it's visible
                video.srcObject = stream;
                video.style.display = 'block';
                video.style.transform = 'scaleX(-1)'; // Mirror the video horizontally
                video.style.setProperty('transform', 'scaleX(-1)', 'important'); // Force with !important
                
                // Debug transform after setting
                console.log('Video transform after setting:', video.style.transform);
                console.log('Video computed style after:', window.getComputedStyle(video).transform);
                
                // Wait for video to be ready and auto-play
                await new Promise((resolve) => {
                    video.onloadedmetadata = () => {
                        video.play().then(() => {
                            console.log('Real camera started successfully');
                            const cameraStatus = document.getElementById('cameraStatus');
                            if (cameraStatus) {
                                cameraStatus.textContent = `Camera: Active (${video.videoWidth}x${video.videoHeight})`;
                                cameraStatus.style.background = 'rgba(0,255,0,0.8)';
                            }
                            resolve();
                        }).catch(e => {
                            console.error('Video play failed:', e);
                            resolve();
                        });
                    };
                });
                
                return true;
            } catch (error) {
                console.error('Camera access failed, falling back to mock camera:', error);
                
                // Fallback to mock camera
                video.srcObject = createMockCamera();
                video.style.display = 'block';
                video.style.transform = 'scaleX(-1)'; // Mirror the video horizontally
                video.play();
                
                const cameraStatus = document.getElementById('cameraStatus');
                if (cameraStatus) {
                    cameraStatus.textContent = `Camera: Demo Mode (${error.message})`;
                    cameraStatus.style.background = 'rgba(255,165,0,0.8)';
                }
                return true;
            }
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', async () => {
            setupLEDs();
            
            // Auto-start camera immediately
            const cameraStarted = await autoStartCamera();
            
            // Initialize face detection
            await initializeFaceDetection();
            
            // Check browser compatibility
            const compatibilityIssues = checkBrowserCompatibility();
            if (compatibilityIssues.length > 0) {
                const statusEl = document.getElementById('status');
                statusEl.innerHTML = `Browser Issues: ${compatibilityIssues.join(' ')} <span class="face-indicator" id="faceIndicator"></span>`;
                statusEl.style.background = '#ff6600';
                faceIndicator = document.getElementById('faceIndicator');
            } else {
                if (cameraStarted) {
                    // Both camera and face detection are ready - auto-start detection
                    startFaceDetection();
                } else {
                    const statusText = cameraStarted ? 
                        'Camera active! Waiting for face detection to load...' : 
                        'Browser compatible! Camera access needed - click Start to try again...';
                    document.getElementById('status').innerHTML = `${statusText} <span class="face-indicator" id="faceIndicator"></span>`;
                faceIndicator = document.getElementById('faceIndicator');
                }
            }
            
            document.getElementById('startBtn').onclick = startFaceDetection;
            document.getElementById('stopBtn').onclick = stopFaceDetection;
            document.getElementById('testBtn').onclick = testSmileyPattern;
            document.getElementById('clearBtn').onclick = clearAllLEDs;
            document.getElementById('cameraTestBtn').onclick = autoStartCamera;
        });

        function initThreeJS() {
            console.log('üü¢ initThreeJS called');
            const canvas = document.getElementById('threeCanvas');
            // Initialize Three.js objects globally
            renderer = new THREE.WebGLRenderer({ canvas, alpha: false });
            renderer.setPixelRatio(window.devicePixelRatio);
            renderer.setSize(window.innerWidth, window.innerHeight);
            // Create scene
            scene = new THREE.Scene();
            // Set up camera
            camera = new THREE.PerspectiveCamera(105, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 0, 5);
            camera.updateProjectionMatrix();
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
            directionalLight.position.set(5, 10, 7.5);
            scene.add(directionalLight);

            // Create LED cube grid
            threeLEDCubes = []; // Reset grid cubes
            const cubeSize = 0.4;            
            const spacing = 0.5;
            const offset = (16 * spacing) / 2;
            for (let row = 0; row < 16; row++) {
                for (let col = 0; col < 16; col++) {
                    const geometry = new THREE.BoxGeometry(cubeSize, cubeSize, cubeSize);
                    const material = new THREE.MeshStandardMaterial({ color: 0x111111, transparent: true, opacity: 0.3 });
                    const cube = new THREE.Mesh(geometry, material);
                    cube.position.x = col * spacing - offset;
                    cube.position.y = -(row * spacing) + offset;
                    scene.add(cube);
                    threeLEDCubes.push(cube);
                }
            }

            // Initial render of LED cubes
            renderer.render(scene, camera);
        }
    </script>
</body>
</html>
